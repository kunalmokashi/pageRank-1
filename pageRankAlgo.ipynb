{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.8\n",
    "tolerance = 10**-10\n",
    "TOP_K = 5\n",
    "dValueForExtraPolation = [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphData(file):\n",
    "    graphEdges = dict()\n",
    "    with open(file) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            lineL = [ int(node) for node in line.strip().split('\\t')]\n",
    "            if graphEdges.get(lineL[0]):\n",
    "                graphEdges[lineL[0]].append(lineL[1])\n",
    "            else:\n",
    "                graphEdges[lineL[0]] = [lineL[1]]\n",
    "            line = fp.readline()\n",
    "    return graphEdges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrixFromGraph(graph, size):\n",
    "    matrix = np.zeros((size, size))\n",
    "    for node in graph.keys():\n",
    "        nodeKey = node\n",
    "        nodeValues = graph.get(node)\n",
    "        nodesCount = len(nodeValues)\n",
    "        eachNodeVal = 1 / nodesCount\n",
    "        # for handling duplicates\n",
    "        valDict = dict()\n",
    "        for val in nodeValues:\n",
    "            if valDict.get(val):\n",
    "                valDict[val] = valDict.get(val) + 1\n",
    "            else:\n",
    "                valDict[val] = 1\n",
    "\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            # To match node and matrix indices: node = matrix indices + 1\n",
    "            count = valDict.get(nodeVal)\n",
    "            matrix[nodeVal-1][node-1] = count * float(eachNodeVal)\n",
    "    return matrix\n",
    "\n",
    "# matrix = createMatrixFromGraph(graphEdges, numberOfNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrixFromGraphWithCount(graph, size):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for node in graph.keys():\n",
    "        nodeKey = node\n",
    "        nodeValues = graph.get(node)\n",
    "        nodesCount = len(nodeValues)\n",
    "        eachNodeVal = 1 / nodesCount\n",
    "        # for handling duplicates\n",
    "        valDict = dict()\n",
    "        for val in nodeValues:\n",
    "            if valDict.get(val):\n",
    "                valDict[val] = valDict.get(val) + 1\n",
    "            else:\n",
    "                valDict[val] = 1\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            # To match node and matrix indices: node = matrix indices + 1\n",
    "            count = valDict.get(nodeVal)\n",
    "            row.append(nodeVal-1)\n",
    "            col.append(node-1)\n",
    "            data.append(count)\n",
    "    matrix = sparse.csr_matrix((data, (row, col)), shape=(size, size))\n",
    "    return matrix\n",
    "\n",
    "# matrixWithCount = createMatrixFromGraph(graphEdges, numberOfNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrixFromGraphSparse(graph, size):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for node in graph.keys():\n",
    "        nodeKey = node\n",
    "        nodeValues = graph.get(node)\n",
    "        nodesCount = len(nodeValues)\n",
    "        eachNodeVal = 1 / nodesCount\n",
    "        # for handling duplicates\n",
    "        valDict = dict()\n",
    "        for val in nodeValues:\n",
    "            if valDict.get(val):\n",
    "                valDict[val] = valDict.get(val) + 1\n",
    "            else:\n",
    "                valDict[val] = 1\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            # To match node and matrix indices: node = matrix indices + 1\n",
    "            count = valDict.get(nodeVal)\n",
    "            row.append(nodeVal-1)\n",
    "            col.append(node-1)\n",
    "            data.append(count * float(eachNodeVal))\n",
    "    matrix = sparse.csr_matrix((data, (row, col)), shape=(size, size))\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMatrixFromGraphSparseWeighted(graph, size):\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for node in graph.keys():\n",
    "        nodeKey = node\n",
    "        nodeValues = graph.get(node)\n",
    "        nodesCount = len(nodeValues)\n",
    "        eachNodeVal = 1 / nodesCount\n",
    "        # for handling duplicates\n",
    "        valDict = dict()\n",
    "        for val in nodeValues:\n",
    "            if valDict.get(val):\n",
    "                valDict[val] = valDict.get(val) + 1\n",
    "            else:\n",
    "                valDict[val] = 1\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            # To match node and matrix indices: node = matrix indices + 1\n",
    "            count = valDict.get(nodeVal)\n",
    "            row.append(nodeVal-1)\n",
    "            col.append(node-1)\n",
    "            data.append(count)\n",
    "    matrix = sparse.csr_matrix((data, (row, col)), shape=(size, size))\n",
    "    \n",
    "    rowSum = matrix.sum(axis=1).T.tolist()[0]\n",
    "    colSum = matrix.sum(axis=0).tolist()[0]\n",
    "    row = []\n",
    "    col = []\n",
    "    data = []\n",
    "    for node in graph.keys():\n",
    "        nodeKey = node\n",
    "        nodeValues = graph.get(node)\n",
    "        nodesCount = len(nodeValues)\n",
    "        eachNodeVal = 1 / nodesCount\n",
    "        # for handling duplicates\n",
    "        valDict = dict()\n",
    "        for val in nodeValues:\n",
    "            if valDict.get(val):\n",
    "                valDict[val] = valDict.get(val) + 1\n",
    "            else:\n",
    "                valDict[val] = 1\n",
    "        #nodeInWeightForNodeChildren\n",
    "        sumNodeIn = 0\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            sumNodeIn = sumNodeIn + rowSum[nodeVal-1]\n",
    "        #nodeOutWeightForNodeChildren\n",
    "        sumNodeOut = 0\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            sumNodeOut = sumNodeIn + colSum[nodeVal-1]\n",
    "        for nodeVal in list(set(nodeValues)):\n",
    "            # To match node and matrix indices: node = matrix indices + 1\n",
    "            nodeInC = rowSum[nodeVal-1]\n",
    "            weightIn = float(nodeInC/sumNodeIn)\n",
    "            \n",
    "            nodeOutC = colSum[nodeVal-1]\n",
    "            weightOut =float(nodeOutC/sumNodeOut)\n",
    "            row.append(nodeVal-1)\n",
    "            col.append(node-1)\n",
    "            data.append(weightIn*weightOut)\n",
    "    matrixNew = sparse.csr_matrix((data, (row, col)), shape=(size, size))\n",
    "    return matrixNew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerIter(sparseMatrix):\n",
    "    # Given, 1 is one vector with nx1 entries of value 1\n",
    "    one = np.ones((numberOfNodes,1))\n",
    "\n",
    "    # initialising the r0\n",
    "    r = 1/ float(numberOfNodes) * one\n",
    "    count = 0\n",
    "    while True:\n",
    "        count += 1\n",
    "        rnew = ((1-beta)/numberOfNodes) * one + beta * sparseMatrix.dot(r)\n",
    "        l1Norm = np.linalg.norm(abs(rnew - r), ord=1)\n",
    "        if l1Norm < tolerance:\n",
    "            break\n",
    "        r = rnew\n",
    "    print('Number of iterations it took is ', count)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerExtrapolation(transitionMatrix, numberOfNodes):\n",
    "    dValues = dValueForExtraPolation\n",
    "    dName = dValues[0]\n",
    "    pageRankD = {}\n",
    "    residualsD = {}\n",
    "    for d in dValues:\n",
    "        pageRankItr = []\n",
    "        pageRankInitial = 1 / numberOfNodes * np.ones((numberOfNodes, 1))\n",
    "        k = 0\n",
    "        res = {}\n",
    "        pageRankItr.append(pageRankInitial)\n",
    "        while True:\n",
    "            k += 1\n",
    "            pageRankNext = (1 - beta) / numberOfNodes * np.ones((numberOfNodes, 1)) + beta * transitionMatrix.dot(pageRankInitial)\n",
    "            if k == d + 2:\n",
    "                pageRankNext = (pageRankNext - (beta**d)*pageRankItr[k - d]) / (1 - beta**d)\n",
    "            error = np.linalg.norm(abs(pageRankNext - pageRankInitial), ord=1)\n",
    "            res[k] = error\n",
    "            if error < tolerance:\n",
    "                pageRankItr.append(pageRankNext)\n",
    "                break\n",
    "            pageRankItr.append(pageRankNext)\n",
    "            pageRankInitial = pageRankNext\n",
    "        pageRankD[d] = pageRankItr\n",
    "        residualsD[d] = res\n",
    "        print('Number of iterations in power extrapolation it took is ', k)\n",
    "    return pageRankD.get(dName)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValuesTuple(indices, r):\n",
    "    return [(r[index][0], index+1) for index in indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTopBottomK(topK,r):\n",
    "    # Top k page ranks with values\n",
    "    topKPagesId = r.T[0].argsort()[-topK:][::-1]\n",
    "    topKPages = getValuesTuple(topKPagesId,r)\n",
    "    print('************Top k node ids with scores************')\n",
    "    for pr in enumerate(topKPages):\n",
    "        (index, (pRVal, nodeId)) = pr\n",
    "        print('Page rank ', index+1, 'for page id ',nodeId+1,'with value is - ', pRVal)\n",
    "\n",
    "    print('\\n\\n')\n",
    "\n",
    "    # Bottom 5 page ranks with values\n",
    "    bottomKPagesId = r.T[0].argsort()[:topK]\n",
    "    bottomKPages = getValuesTuple(bottomKPagesId,r)\n",
    "    print('************Bottom k node ids with scores************')\n",
    "    for pr in enumerate(bottomKPages):\n",
    "        (index, (pRVal, nodeId)) = pr\n",
    "        print('Page rank ', index+1, 'for page id ',nodeId+1,'with value is - ', pRVal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes using is 281903\n",
      "Number of non zero points is  2312497\n"
     ]
    }
   ],
   "source": [
    "graphEdges = getGraphData('web-Stanford.txt')\n",
    "numberOfNodes = sorted(graphEdges.keys(), reverse=True)[:1][0]\n",
    "print(\"Number of nodes using is\", numberOfNodes)\n",
    "sparseMatrix = createMatrixFromGraphSparse(graphEdges, numberOfNodes)\n",
    "sparseMatrixWeighted = createMatrixFromGraphSparseWeighted(graphEdges, numberOfNodes)\n",
    "numberOfNonZeroEdges = sparse.csr_matrix.count_nonzero(sparseMatrix)\n",
    "print('Number of non zero points is ',numberOfNonZeroEdges)\n",
    "# powerRankVec, residualsR = powerExtrapolationPagerank(sparseMatrixWeighted, numberOfNodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations it took is  87\n",
      "Normal page rank with power iteration\n",
      "************Top k node ids with scores************\n",
      "Page rank  1 for page id  89074 with value is -  0.010474629007599982\n",
      "Page rank  2 for page id  226412 with value is -  0.009610237778224624\n",
      "Page rank  3 for page id  241455 with value is -  0.008379659180575367\n",
      "Page rank  4 for page id  134833 with value is -  0.0032578572592821694\n",
      "Page rank  5 for page id  69359 with value is -  0.0027316738913733996\n",
      "\n",
      "\n",
      "\n",
      "************Bottom k node ids with scores************\n",
      "Page rank  1 for page id  2 with value is -  7.094638936087944e-07\n",
      "Page rank  2 for page id  21387 with value is -  7.094638936087944e-07\n",
      "Page rank  3 for page id  87192 with value is -  7.094638936087944e-07\n",
      "Page rank  4 for page id  205726 with value is -  7.094638936087944e-07\n",
      "Page rank  5 for page id  205720 with value is -  7.094638936087944e-07\n"
     ]
    }
   ],
   "source": [
    "# Using normal page rank and power iteration\n",
    "r = powerIter(sparseMatrix)\n",
    "print(\"Normal page rank with power iteration\")\n",
    "getTopBottomK(TOP_K,r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations in power extrapolation it took is  75\n",
      "Normal page rank with power extrapolation\n",
      "************Top k node ids with scores************\n",
      "Page rank  1 for page id  89074 with value is -  0.010474629005360647\n",
      "Page rank  2 for page id  226412 with value is -  0.009610237776892454\n",
      "Page rank  3 for page id  241455 with value is -  0.00837965917897915\n",
      "Page rank  4 for page id  134833 with value is -  0.003257857259166489\n",
      "Page rank  5 for page id  69359 with value is -  0.002731673891306296\n",
      "\n",
      "\n",
      "\n",
      "************Bottom k node ids with scores************\n",
      "Page rank  1 for page id  2 with value is -  7.094638936087944e-07\n",
      "Page rank  2 for page id  21387 with value is -  7.094638936087944e-07\n",
      "Page rank  3 for page id  87192 with value is -  7.094638936087944e-07\n",
      "Page rank  4 for page id  205726 with value is -  7.094638936087944e-07\n",
      "Page rank  5 for page id  205720 with value is -  7.094638936087944e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using normal page rank and power extrapolation\n",
    "r = powerExtrapolation(sparseMatrix, numberOfNodes)\n",
    "print(\"Normal page rank with power extrapolation\")\n",
    "getTopBottomK(TOP_K,r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations it took is  18\n",
      "Normal page rank with power iteration\n",
      "************Top k node ids with scores************\n",
      "Page rank  1 for page id  82869 with value is -  0.00010306948712871268\n",
      "Page rank  2 for page id  160278 with value is -  7.603265457011555e-05\n",
      "Page rank  3 for page id  27685 with value is -  7.224273255526352e-05\n",
      "Page rank  4 for page id  25636 with value is -  6.72899123907457e-05\n",
      "Page rank  5 for page id  20707 with value is -  6.672859648514436e-05\n",
      "\n",
      "\n",
      "\n",
      "************Bottom k node ids with scores************\n",
      "Page rank  1 for page id  2 with value is -  7.094638936087944e-07\n",
      "Page rank  2 for page id  185682 with value is -  7.094638936087944e-07\n",
      "Page rank  3 for page id  185689 with value is -  7.094638936087944e-07\n",
      "Page rank  4 for page id  185698 with value is -  7.094638936087944e-07\n",
      "Page rank  5 for page id  185701 with value is -  7.094638936087944e-07\n"
     ]
    }
   ],
   "source": [
    "# Using weighted page rank and power iteration\n",
    "r = powerIter(sparseMatrixWeighted)\n",
    "print(\"Normal page rank with power iteration\")\n",
    "getTopBottomK(TOP_K,r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations in power extrapolation it took is  24\n",
      "Normal page rank with power extrapolation\n",
      "************Top k node ids with scores************\n",
      "Page rank  1 for page id  82869 with value is -  0.00010306948712871268\n",
      "Page rank  2 for page id  160278 with value is -  7.603265457011554e-05\n",
      "Page rank  3 for page id  27685 with value is -  7.224273255526352e-05\n",
      "Page rank  4 for page id  25636 with value is -  6.72899123907437e-05\n",
      "Page rank  5 for page id  20707 with value is -  6.672859648514235e-05\n",
      "\n",
      "\n",
      "\n",
      "************Bottom k node ids with scores************\n",
      "Page rank  1 for page id  2 with value is -  7.094638936087944e-07\n",
      "Page rank  2 for page id  185682 with value is -  7.094638936087944e-07\n",
      "Page rank  3 for page id  185689 with value is -  7.094638936087944e-07\n",
      "Page rank  4 for page id  185698 with value is -  7.094638936087944e-07\n",
      "Page rank  5 for page id  185701 with value is -  7.094638936087944e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using weighted page rank and power extrapolation\n",
    "r = powerExtrapolation(sparseMatrixWeighted,numberOfNodes)\n",
    "print(\"Normal page rank with power extrapolation\")\n",
    "getTopBottomK(TOP_K,r)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
